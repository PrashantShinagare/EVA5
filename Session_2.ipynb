{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrashantShinagare/EVA5/blob/master/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function         # Imports the newer features of print (which is a function), in case, using older version of python\n",
        "import torch                                  # Import torch library\n",
        "import torch.nn as nn                         # Import torch.nn module that helps in creating and training of the neural network.  \n",
        "import torch.nn.functional as F               # Import nn.functional module that contain useful functions such as activation function.\n",
        "import torch.optim as optim                   # Import nn.optim that implements various optimization algorithms. \n",
        "from torchvision import datasets, transforms  # Import datasets and transforms from torchvision which houses popular datasets, model architectures, and\n",
        "                                              # common image transformations. "
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):                               # create a class named Net with \n",
        "    def __init__(self):                             # All classes have __init__() function which is always executed with class is created with self parameter that references to the current instance of the class and to access variables that belong to that class. It need not be named \"self\" and can be any called with whatever name but has to be the first parameter of any function in the class.\n",
        "        super(Net, self).__init__()                 # Inherit all the methods and functions of parents class (nn.module in this case)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1) #input -? OUtput? RF\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3)\n",
        "        self.conv6 = nn.Conv2d(256, 512, 3)\n",
        "        self.conv7 = nn.Conv2d(512, 10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "a68006ac-4439-4e7a-d801-758a662ca888"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()                    # Determines if the systeme supports CUDA\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")    # uses CUDA if available from previous step or uses CPU\n",
        "model = Net().to(device)                                # Connecting the constructied nueral net class the device \n",
        "print (model)                               \n",
        "summary(model, input_size=(1, 28, 28))                  #   "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Net(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv7): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "            Conv2d-2           [-1, 32, 28, 28]           4,640\n",
            "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
            "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
            "            Conv2d-5          [-1, 128, 14, 14]          73,856\n",
            "         MaxPool2d-6            [-1, 128, 7, 7]               0\n",
            "            Conv2d-7            [-1, 256, 5, 5]         295,168\n",
            "            Conv2d-8            [-1, 512, 3, 3]       1,180,160\n",
            "            Conv2d-9             [-1, 10, 1, 1]          46,090\n",
            "================================================================\n",
            "Total params: 1,618,570\n",
            "Trainable params: 1,618,570\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.75\n",
            "Params size (MB): 6.17\n",
            "Estimated Total Size (MB): 6.93\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(4)\n",
        "batch_size = 64\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}    # Keyword arguments (kwargs) are used as key:value pair and are used to pass keyword argument and also any number of them.\n",
        "train_loader = torch.utils.data.DataLoader(                           \n",
        "    datasets.MNIST('../data', train=True, download=True,               # Load the training dataset\n",
        "                    transform=transforms.Compose([                     # Compose clubs all the transforms provided and all these transformations are applied to the input one by one.\n",
        "                        transforms.ToTensor(),                         # Converts input image to pytorch tensor\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))     # this is input data scaling and these values (mean and std) must have been precomputed for the dataset. \n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([     # Load the validation dataset\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c756b6e4-4a60-4075-ea50-076f4560510f"
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=.9) # Implements Stochastic gradient descent \n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\n",
            "loss=2.302652359008789 batch_id=0:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "loss=2.3035428524017334 batch_id=1:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "loss=2.3035428524017334 batch_id=1:   0%|          | 2/469 [00:00<00:29, 15.76it/s]\u001b[A\n",
            "loss=2.3020009994506836 batch_id=2:   0%|          | 2/469 [00:00<00:29, 15.76it/s]\u001b[A\n",
            "loss=2.303995370864868 batch_id=3:   0%|          | 2/469 [00:00<00:29, 15.76it/s] \u001b[A\n",
            "loss=2.3033642768859863 batch_id=4:   0%|          | 2/469 [00:00<00:29, 15.76it/s]\u001b[A\n",
            "loss=2.3033642768859863 batch_id=4:   1%|          | 5/469 [00:00<00:25, 18.16it/s]\u001b[A\n",
            "loss=2.3013203144073486 batch_id=5:   1%|          | 5/469 [00:00<00:25, 18.16it/s]\u001b[A\n",
            "loss=2.302285671234131 batch_id=6:   1%|          | 5/469 [00:00<00:25, 18.16it/s] \u001b[A\n",
            "loss=2.3029375076293945 batch_id=7:   1%|          | 5/469 [00:00<00:25, 18.16it/s]\u001b[A\n",
            "loss=2.3029375076293945 batch_id=7:   2%|▏         | 8/469 [00:00<00:23, 19.96it/s]\u001b[A\n",
            "loss=2.3030829429626465 batch_id=8:   2%|▏         | 8/469 [00:00<00:23, 19.96it/s]\u001b[A\n",
            "loss=2.3034446239471436 batch_id=9:   2%|▏         | 8/469 [00:00<00:23, 19.96it/s]\u001b[A\n",
            "loss=2.30173397064209 batch_id=10:   2%|▏         | 8/469 [00:00<00:23, 19.96it/s] \u001b[A\n",
            "loss=2.30173397064209 batch_id=10:   2%|▏         | 11/469 [00:00<00:20, 21.99it/s]\u001b[A\n",
            "loss=2.3026609420776367 batch_id=11:   2%|▏         | 11/469 [00:00<00:20, 21.99it/s]\u001b[A\n",
            "loss=2.3021128177642822 batch_id=12:   2%|▏         | 11/469 [00:00<00:20, 21.99it/s]\u001b[A\n",
            "loss=2.3032851219177246 batch_id=13:   2%|▏         | 11/469 [00:00<00:20, 21.99it/s]\u001b[A\n",
            "loss=2.3032851219177246 batch_id=13:   3%|▎         | 14/469 [00:00<00:19, 23.77it/s]\u001b[A\n",
            "loss=2.302069902420044 batch_id=14:   3%|▎         | 14/469 [00:00<00:19, 23.77it/s] \u001b[A\n",
            "loss=2.3028950691223145 batch_id=15:   3%|▎         | 14/469 [00:00<00:19, 23.77it/s]\u001b[A\n",
            "loss=2.3014237880706787 batch_id=16:   3%|▎         | 14/469 [00:00<00:19, 23.77it/s]\u001b[A\n",
            "loss=2.3009984493255615 batch_id=17:   3%|▎         | 14/469 [00:00<00:19, 23.77it/s]\u001b[A\n",
            "loss=2.3009984493255615 batch_id=17:   4%|▍         | 18/469 [00:00<00:16, 26.63it/s]\u001b[A\n",
            "loss=2.301693916320801 batch_id=18:   4%|▍         | 18/469 [00:00<00:16, 26.63it/s] \u001b[A\n",
            "loss=2.302110433578491 batch_id=19:   4%|▍         | 18/469 [00:00<00:16, 26.63it/s]\u001b[A\n",
            "loss=2.302152156829834 batch_id=20:   4%|▍         | 18/469 [00:00<00:16, 26.63it/s]\u001b[A\n",
            "loss=2.302152156829834 batch_id=20:   4%|▍         | 21/469 [00:00<00:16, 26.74it/s]\u001b[A\n",
            "loss=2.3010075092315674 batch_id=21:   4%|▍         | 21/469 [00:00<00:16, 26.74it/s]\u001b[A\n",
            "loss=2.302799940109253 batch_id=22:   4%|▍         | 21/469 [00:00<00:16, 26.74it/s] \u001b[A\n",
            "loss=2.3006489276885986 batch_id=23:   4%|▍         | 21/469 [00:00<00:16, 26.74it/s]\u001b[A\n",
            "loss=2.3006489276885986 batch_id=23:   5%|▌         | 24/469 [00:00<00:16, 27.52it/s]\u001b[A\n",
            "loss=2.301795721054077 batch_id=24:   5%|▌         | 24/469 [00:00<00:16, 27.52it/s] \u001b[A\n",
            "loss=2.3023452758789062 batch_id=25:   5%|▌         | 24/469 [00:00<00:16, 27.52it/s]\u001b[A\n",
            "loss=2.301137685775757 batch_id=26:   5%|▌         | 24/469 [00:00<00:16, 27.52it/s] \u001b[A\n",
            "loss=2.301137685775757 batch_id=26:   6%|▌         | 27/469 [00:00<00:15, 27.65it/s]\u001b[A\n",
            "loss=2.2997324466705322 batch_id=27:   6%|▌         | 27/469 [00:01<00:15, 27.65it/s]\u001b[A\n",
            "loss=2.3008594512939453 batch_id=28:   6%|▌         | 27/469 [00:01<00:15, 27.65it/s]\u001b[A\n",
            "loss=2.3022048473358154 batch_id=29:   6%|▌         | 27/469 [00:01<00:15, 27.65it/s]\u001b[A\n",
            "loss=2.3016722202301025 batch_id=30:   6%|▌         | 27/469 [00:01<00:15, 27.65it/s]\u001b[A\n",
            "loss=2.3016722202301025 batch_id=30:   7%|▋         | 31/469 [00:01<00:15, 28.32it/s]\u001b[A\n",
            "loss=2.3003358840942383 batch_id=31:   7%|▋         | 31/469 [00:01<00:15, 28.32it/s]\u001b[A\n",
            "loss=2.3009626865386963 batch_id=32:   7%|▋         | 31/469 [00:01<00:15, 28.32it/s]\u001b[A\n",
            "loss=2.300785779953003 batch_id=33:   7%|▋         | 31/469 [00:01<00:15, 28.32it/s] \u001b[A\n",
            "loss=2.300785779953003 batch_id=33:   7%|▋         | 34/469 [00:01<00:15, 27.92it/s]\u001b[A\n",
            "loss=2.3022000789642334 batch_id=34:   7%|▋         | 34/469 [00:01<00:15, 27.92it/s]\u001b[A\n",
            "loss=2.3009657859802246 batch_id=35:   7%|▋         | 34/469 [00:01<00:15, 27.92it/s]\u001b[A\n",
            "loss=2.2997324466705322 batch_id=36:   7%|▋         | 34/469 [00:01<00:15, 27.92it/s]\u001b[A\n",
            "loss=2.2997324466705322 batch_id=36:   8%|▊         | 37/469 [00:01<00:15, 28.08it/s]\u001b[A\n",
            "loss=2.3011269569396973 batch_id=37:   8%|▊         | 37/469 [00:01<00:15, 28.08it/s]\u001b[A\n",
            "loss=2.301568031311035 batch_id=38:   8%|▊         | 37/469 [00:01<00:15, 28.08it/s] \u001b[A\n",
            "loss=2.3019917011260986 batch_id=39:   8%|▊         | 37/469 [00:01<00:15, 28.08it/s]\u001b[A\n",
            "loss=2.3016412258148193 batch_id=40:   8%|▊         | 37/469 [00:01<00:15, 28.08it/s]\u001b[A\n",
            "loss=2.3016412258148193 batch_id=40:   9%|▊         | 41/469 [00:01<00:14, 28.79it/s]\u001b[A\n",
            "loss=2.301691770553589 batch_id=41:   9%|▊         | 41/469 [00:01<00:14, 28.79it/s] \u001b[A\n",
            "loss=2.3008053302764893 batch_id=42:   9%|▊         | 41/469 [00:01<00:14, 28.79it/s]\u001b[A\n",
            "loss=2.300149440765381 batch_id=43:   9%|▊         | 41/469 [00:01<00:14, 28.79it/s] \u001b[A\n",
            "loss=2.300659656524658 batch_id=44:   9%|▊         | 41/469 [00:01<00:14, 28.79it/s]\u001b[A\n",
            "loss=2.300659656524658 batch_id=44:  10%|▉         | 45/469 [00:01<00:14, 30.12it/s]\u001b[A\n",
            "loss=2.301457405090332 batch_id=45:  10%|▉         | 45/469 [00:01<00:14, 30.12it/s]\u001b[A\n",
            "loss=2.3020641803741455 batch_id=46:  10%|▉         | 45/469 [00:01<00:14, 30.12it/s]\u001b[A\n",
            "loss=2.3002209663391113 batch_id=47:  10%|▉         | 45/469 [00:01<00:14, 30.12it/s]\u001b[A\n",
            "loss=2.3016648292541504 batch_id=48:  10%|▉         | 45/469 [00:01<00:14, 30.12it/s]\u001b[A\n",
            "loss=2.3016648292541504 batch_id=48:  10%|█         | 49/469 [00:01<00:13, 30.46it/s]\u001b[A\n",
            "loss=2.3007540702819824 batch_id=49:  10%|█         | 49/469 [00:01<00:13, 30.46it/s]\u001b[A\n",
            "loss=2.299683094024658 batch_id=50:  10%|█         | 49/469 [00:01<00:13, 30.46it/s] \u001b[A\n",
            "loss=2.3020553588867188 batch_id=51:  10%|█         | 49/469 [00:01<00:13, 30.46it/s]\u001b[A\n",
            "loss=2.300891876220703 batch_id=52:  10%|█         | 49/469 [00:01<00:13, 30.46it/s] \u001b[A\n",
            "loss=2.300891876220703 batch_id=52:  11%|█▏        | 53/469 [00:01<00:13, 29.87it/s]\u001b[A\n",
            "loss=2.2986559867858887 batch_id=53:  11%|█▏        | 53/469 [00:01<00:13, 29.87it/s]\u001b[A\n",
            "loss=2.298452854156494 batch_id=54:  11%|█▏        | 53/469 [00:01<00:13, 29.87it/s] \u001b[A\n",
            "loss=2.3001813888549805 batch_id=55:  11%|█▏        | 53/469 [00:01<00:13, 29.87it/s]\u001b[A\n",
            "loss=2.2992398738861084 batch_id=56:  11%|█▏        | 53/469 [00:01<00:13, 29.87it/s]\u001b[A\n",
            "loss=2.2992398738861084 batch_id=56:  12%|█▏        | 57/469 [00:01<00:14, 29.36it/s]\u001b[A\n",
            "loss=2.2990455627441406 batch_id=57:  12%|█▏        | 57/469 [00:02<00:14, 29.36it/s]\u001b[A\n",
            "loss=2.301110029220581 batch_id=58:  12%|█▏        | 57/469 [00:02<00:14, 29.36it/s] \u001b[A\n",
            "loss=2.2998881340026855 batch_id=59:  12%|█▏        | 57/469 [00:02<00:14, 29.36it/s]\u001b[A\n",
            "loss=2.2998881340026855 batch_id=59:  13%|█▎        | 60/469 [00:02<00:13, 29.29it/s]\u001b[A\n",
            "loss=2.2999491691589355 batch_id=60:  13%|█▎        | 60/469 [00:02<00:13, 29.29it/s]\u001b[A\n",
            "loss=2.298520088195801 batch_id=61:  13%|█▎        | 60/469 [00:02<00:13, 29.29it/s] \u001b[A\n",
            "loss=2.299579620361328 batch_id=62:  13%|█▎        | 60/469 [00:02<00:13, 29.29it/s]\u001b[A\n",
            "loss=2.299579620361328 batch_id=62:  13%|█▎        | 63/469 [00:02<00:13, 29.04it/s]\u001b[A\n",
            "loss=2.3008203506469727 batch_id=63:  13%|█▎        | 63/469 [00:02<00:13, 29.04it/s]\u001b[A\n",
            "loss=2.300236940383911 batch_id=64:  13%|█▎        | 63/469 [00:02<00:13, 29.04it/s] \u001b[A\n",
            "loss=2.2989342212677 batch_id=65:  13%|█▎        | 63/469 [00:02<00:13, 29.04it/s]  \u001b[A\n",
            "loss=2.2989342212677 batch_id=65:  14%|█▍        | 66/469 [00:02<00:13, 29.17it/s]\u001b[A\n",
            "loss=2.2995786666870117 batch_id=66:  14%|█▍        | 66/469 [00:02<00:13, 29.17it/s]\u001b[A\n",
            "loss=2.2987022399902344 batch_id=67:  14%|█▍        | 66/469 [00:02<00:13, 29.17it/s]\u001b[A\n",
            "loss=2.299675226211548 batch_id=68:  14%|█▍        | 66/469 [00:02<00:13, 29.17it/s] \u001b[A\n",
            "loss=2.299675226211548 batch_id=68:  15%|█▍        | 69/469 [00:02<00:13, 28.59it/s]\u001b[A\n",
            "loss=2.2994728088378906 batch_id=69:  15%|█▍        | 69/469 [00:02<00:13, 28.59it/s]\u001b[A\n",
            "loss=2.2970049381256104 batch_id=70:  15%|█▍        | 69/469 [00:02<00:13, 28.59it/s]\u001b[A\n",
            "loss=2.3003458976745605 batch_id=71:  15%|█▍        | 69/469 [00:02<00:13, 28.59it/s]\u001b[A\n",
            "loss=2.2986438274383545 batch_id=72:  15%|█▍        | 69/469 [00:02<00:13, 28.59it/s]\u001b[A\n",
            "loss=2.2986438274383545 batch_id=72:  16%|█▌        | 73/469 [00:02<00:13, 29.51it/s]\u001b[A\n",
            "loss=2.2984459400177 batch_id=73:  16%|█▌        | 73/469 [00:02<00:13, 29.51it/s]   \u001b[A\n",
            "loss=2.297170400619507 batch_id=74:  16%|█▌        | 73/469 [00:02<00:13, 29.51it/s]\u001b[A\n",
            "loss=2.2978532314300537 batch_id=75:  16%|█▌        | 73/469 [00:02<00:13, 29.51it/s]\u001b[A\n",
            "loss=2.2978532314300537 batch_id=75:  16%|█▌        | 76/469 [00:02<00:13, 29.35it/s]\u001b[A\n",
            "loss=2.29836106300354 batch_id=76:  16%|█▌        | 76/469 [00:02<00:13, 29.35it/s]  \u001b[A\n",
            "loss=2.299650192260742 batch_id=77:  16%|█▌        | 76/469 [00:02<00:13, 29.35it/s]\u001b[A\n",
            "loss=2.2970049381256104 batch_id=78:  16%|█▌        | 76/469 [00:02<00:13, 29.35it/s]\u001b[A\n",
            "loss=2.2970049381256104 batch_id=78:  17%|█▋        | 79/469 [00:02<00:13, 28.52it/s]\u001b[A\n",
            "loss=2.295865535736084 batch_id=79:  17%|█▋        | 79/469 [00:02<00:13, 28.52it/s] \u001b[A\n",
            "loss=2.2995800971984863 batch_id=80:  17%|█▋        | 79/469 [00:02<00:13, 28.52it/s]\u001b[A\n",
            "loss=2.296856641769409 batch_id=81:  17%|█▋        | 79/469 [00:02<00:13, 28.52it/s] \u001b[A\n",
            "loss=2.296856641769409 batch_id=81:  17%|█▋        | 82/469 [00:02<00:13, 28.02it/s]\u001b[A\n",
            "loss=2.2993431091308594 batch_id=82:  17%|█▋        | 82/469 [00:02<00:13, 28.02it/s]\u001b[A\n",
            "loss=2.300577402114868 batch_id=83:  17%|█▋        | 82/469 [00:02<00:13, 28.02it/s] \u001b[A\n",
            "loss=2.298220634460449 batch_id=84:  17%|█▋        | 82/469 [00:02<00:13, 28.02it/s]\u001b[A\n",
            "loss=2.2992024421691895 batch_id=85:  17%|█▋        | 82/469 [00:02<00:13, 28.02it/s]\u001b[A\n",
            "loss=2.2992024421691895 batch_id=85:  18%|█▊        | 86/469 [00:02<00:13, 28.95it/s]\u001b[A\n",
            "loss=2.2977845668792725 batch_id=86:  18%|█▊        | 86/469 [00:03<00:13, 28.95it/s]\u001b[A\n",
            "loss=2.2980902194976807 batch_id=87:  18%|█▊        | 86/469 [00:03<00:13, 28.95it/s]\u001b[A\n",
            "loss=2.298588752746582 batch_id=88:  18%|█▊        | 86/469 [00:03<00:13, 28.95it/s] \u001b[A\n",
            "loss=2.2977960109710693 batch_id=89:  18%|█▊        | 86/469 [00:03<00:13, 28.95it/s]\u001b[A\n",
            "loss=2.2977960109710693 batch_id=89:  19%|█▉        | 90/469 [00:03<00:12, 29.59it/s]\u001b[A\n",
            "loss=2.2963645458221436 batch_id=90:  19%|█▉        | 90/469 [00:03<00:12, 29.59it/s]\u001b[A\n",
            "loss=2.296525478363037 batch_id=91:  19%|█▉        | 90/469 [00:03<00:12, 29.59it/s] \u001b[A\n",
            "loss=2.2945356369018555 batch_id=92:  19%|█▉        | 90/469 [00:03<00:12, 29.59it/s]\u001b[A\n",
            "loss=2.2945356369018555 batch_id=92:  20%|█▉        | 93/469 [00:03<00:12, 28.93it/s]\u001b[A\n",
            "loss=2.300313711166382 batch_id=93:  20%|█▉        | 93/469 [00:03<00:12, 28.93it/s] \u001b[A\n",
            "loss=2.2974255084991455 batch_id=94:  20%|█▉        | 93/469 [00:03<00:12, 28.93it/s]\u001b[A\n",
            "loss=2.2965714931488037 batch_id=95:  20%|█▉        | 93/469 [00:03<00:12, 28.93it/s]\u001b[A\n",
            "loss=2.2965714931488037 batch_id=95:  20%|██        | 96/469 [00:03<00:12, 28.80it/s]\u001b[A\n",
            "loss=2.2982289791107178 batch_id=96:  20%|██        | 96/469 [00:03<00:12, 28.80it/s]\u001b[A\n",
            "loss=2.2954986095428467 batch_id=97:  20%|██        | 96/469 [00:03<00:12, 28.80it/s]\u001b[A\n",
            "loss=2.300020694732666 batch_id=98:  20%|██        | 96/469 [00:03<00:12, 28.80it/s] \u001b[A\n",
            "loss=2.2985544204711914 batch_id=99:  20%|██        | 96/469 [00:03<00:12, 28.80it/s]\u001b[A\n",
            "loss=2.2985544204711914 batch_id=99:  21%|██▏       | 100/469 [00:03<00:12, 29.68it/s]\u001b[A\n",
            "loss=2.297576665878296 batch_id=100:  21%|██▏       | 100/469 [00:03<00:12, 29.68it/s]\u001b[A\n",
            "loss=2.2955379486083984 batch_id=101:  21%|██▏       | 100/469 [00:03<00:12, 29.68it/s]\u001b[A\n",
            "loss=2.2968811988830566 batch_id=102:  21%|██▏       | 100/469 [00:03<00:12, 29.68it/s]\u001b[A\n",
            "loss=2.2968811988830566 batch_id=102:  22%|██▏       | 103/469 [00:03<00:12, 28.90it/s]\u001b[A\n",
            "loss=2.2953083515167236 batch_id=103:  22%|██▏       | 103/469 [00:03<00:12, 28.90it/s]\u001b[A\n",
            "loss=2.296066999435425 batch_id=104:  22%|██▏       | 103/469 [00:03<00:12, 28.90it/s] \u001b[A\n",
            "loss=2.296097993850708 batch_id=105:  22%|██▏       | 103/469 [00:03<00:12, 28.90it/s]\u001b[A\n",
            "loss=2.296097993850708 batch_id=105:  23%|██▎       | 106/469 [00:03<00:12, 28.75it/s]\u001b[A\n",
            "loss=2.2968637943267822 batch_id=106:  23%|██▎       | 106/469 [00:03<00:12, 28.75it/s]\u001b[A\n",
            "loss=2.2966039180755615 batch_id=107:  23%|██▎       | 106/469 [00:03<00:12, 28.75it/s]\u001b[A\n",
            "loss=2.2963201999664307 batch_id=108:  23%|██▎       | 106/469 [00:03<00:12, 28.75it/s]\u001b[A\n",
            "loss=2.2963201999664307 batch_id=108:  23%|██▎       | 109/469 [00:03<00:12, 28.47it/s]\u001b[A\n",
            "loss=2.2958714962005615 batch_id=109:  23%|██▎       | 109/469 [00:03<00:12, 28.47it/s]\u001b[A\n",
            "loss=2.2975449562072754 batch_id=110:  23%|██▎       | 109/469 [00:03<00:12, 28.47it/s]\u001b[A\n",
            "loss=2.296424150466919 batch_id=111:  23%|██▎       | 109/469 [00:03<00:12, 28.47it/s] \u001b[A\n",
            "loss=2.2969412803649902 batch_id=112:  23%|██▎       | 109/469 [00:03<00:12, 28.47it/s]\u001b[A\n",
            "loss=2.2969412803649902 batch_id=112:  24%|██▍       | 113/469 [00:03<00:12, 29.49it/s]\u001b[A\n",
            "loss=2.2948174476623535 batch_id=113:  24%|██▍       | 113/469 [00:03<00:12, 29.49it/s]\u001b[A\n",
            "loss=2.2970235347747803 batch_id=114:  24%|██▍       | 113/469 [00:03<00:12, 29.49it/s]\u001b[A\n",
            "loss=2.297089099884033 batch_id=115:  24%|██▍       | 113/469 [00:03<00:12, 29.49it/s] \u001b[A\n",
            "loss=2.2967395782470703 batch_id=116:  24%|██▍       | 113/469 [00:04<00:12, 29.49it/s]\u001b[A\n",
            "loss=2.2967395782470703 batch_id=116:  25%|██▍       | 117/469 [00:04<00:11, 30.13it/s]\u001b[A\n",
            "loss=2.296769380569458 batch_id=117:  25%|██▍       | 117/469 [00:04<00:11, 30.13it/s] \u001b[A\n",
            "loss=2.293771505355835 batch_id=118:  25%|██▍       | 117/469 [00:04<00:11, 30.13it/s]\u001b[A\n",
            "loss=2.2945704460144043 batch_id=119:  25%|██▍       | 117/469 [00:04<00:11, 30.13it/s]\u001b[A\n",
            "loss=2.2933952808380127 batch_id=120:  25%|██▍       | 117/469 [00:04<00:11, 30.13it/s]\u001b[A\n",
            "loss=2.2933952808380127 batch_id=120:  26%|██▌       | 121/469 [00:04<00:11, 30.66it/s]\u001b[A\n",
            "loss=2.2954492568969727 batch_id=121:  26%|██▌       | 121/469 [00:04<00:11, 30.66it/s]\u001b[A\n",
            "loss=2.296801805496216 batch_id=122:  26%|██▌       | 121/469 [00:04<00:11, 30.66it/s] \u001b[A\n",
            "loss=2.2972118854522705 batch_id=123:  26%|██▌       | 121/469 [00:04<00:11, 30.66it/s]\u001b[A\n",
            "loss=2.292654037475586 batch_id=124:  26%|██▌       | 121/469 [00:04<00:11, 30.66it/s] \u001b[A\n",
            "loss=2.292654037475586 batch_id=124:  27%|██▋       | 125/469 [00:04<00:10, 31.57it/s]\u001b[A\n",
            "loss=2.2930591106414795 batch_id=125:  27%|██▋       | 125/469 [00:04<00:10, 31.57it/s]\u001b[A\n",
            "loss=2.297445297241211 batch_id=126:  27%|██▋       | 125/469 [00:04<00:10, 31.57it/s] \u001b[A\n",
            "loss=2.295545816421509 batch_id=127:  27%|██▋       | 125/469 [00:04<00:10, 31.57it/s]\u001b[A\n",
            "loss=2.2963929176330566 batch_id=128:  27%|██▋       | 125/469 [00:04<00:10, 31.57it/s]\u001b[A\n",
            "loss=2.2963929176330566 batch_id=128:  28%|██▊       | 129/469 [00:04<00:11, 30.50it/s]\u001b[A\n",
            "loss=2.2936131954193115 batch_id=129:  28%|██▊       | 129/469 [00:04<00:11, 30.50it/s]\u001b[A\n",
            "loss=2.2934460639953613 batch_id=130:  28%|██▊       | 129/469 [00:04<00:11, 30.50it/s]\u001b[A\n",
            "loss=2.2943227291107178 batch_id=131:  28%|██▊       | 129/469 [00:04<00:11, 30.50it/s]\u001b[A\n",
            "loss=2.296088695526123 batch_id=132:  28%|██▊       | 129/469 [00:04<00:11, 30.50it/s] \u001b[A\n",
            "loss=2.296088695526123 batch_id=132:  28%|██▊       | 133/469 [00:04<00:11, 30.27it/s]\u001b[A\n",
            "loss=2.2966771125793457 batch_id=133:  28%|██▊       | 133/469 [00:04<00:11, 30.27it/s]\u001b[A\n",
            "loss=2.2929844856262207 batch_id=134:  28%|██▊       | 133/469 [00:04<00:11, 30.27it/s]\u001b[A\n",
            "loss=2.292670726776123 batch_id=135:  28%|██▊       | 133/469 [00:04<00:11, 30.27it/s] \u001b[A\n",
            "loss=2.296133518218994 batch_id=136:  28%|██▊       | 133/469 [00:04<00:11, 30.27it/s]\u001b[A\n",
            "loss=2.296133518218994 batch_id=136:  29%|██▉       | 137/469 [00:04<00:11, 29.82it/s]\u001b[A\n",
            "loss=2.2935609817504883 batch_id=137:  29%|██▉       | 137/469 [00:04<00:11, 29.82it/s]\u001b[A\n",
            "loss=2.293910264968872 batch_id=138:  29%|██▉       | 137/469 [00:04<00:11, 29.82it/s] \u001b[A\n",
            "loss=2.2929282188415527 batch_id=139:  29%|██▉       | 137/469 [00:04<00:11, 29.82it/s]\u001b[A\n",
            "loss=2.29264497756958 batch_id=140:  29%|██▉       | 137/469 [00:04<00:11, 29.82it/s]  \u001b[A\n",
            "loss=2.29264497756958 batch_id=140:  30%|███       | 141/469 [00:04<00:10, 32.17it/s]\u001b[A\n",
            "loss=2.2944753170013428 batch_id=141:  30%|███       | 141/469 [00:04<00:10, 32.17it/s]\u001b[A\n",
            "loss=2.29188871383667 batch_id=142:  30%|███       | 141/469 [00:04<00:10, 32.17it/s]  \u001b[A\n",
            "loss=2.2917985916137695 batch_id=143:  30%|███       | 141/469 [00:04<00:10, 32.17it/s]\u001b[A\n",
            "loss=2.2922282218933105 batch_id=144:  30%|███       | 141/469 [00:04<00:10, 32.17it/s]\u001b[A\n",
            "loss=2.2922282218933105 batch_id=144:  31%|███       | 145/469 [00:04<00:10, 30.10it/s]\u001b[A\n",
            "loss=2.2951948642730713 batch_id=145:  31%|███       | 145/469 [00:04<00:10, 30.10it/s]\u001b[A\n",
            "loss=2.296560049057007 batch_id=146:  31%|███       | 145/469 [00:05<00:10, 30.10it/s] \u001b[A\n",
            "loss=2.2948930263519287 batch_id=147:  31%|███       | 145/469 [00:05<00:10, 30.10it/s]\u001b[A\n",
            "loss=2.2930824756622314 batch_id=148:  31%|███       | 145/469 [00:05<00:10, 30.10it/s]\u001b[A\n",
            "loss=2.2930824756622314 batch_id=148:  32%|███▏      | 149/469 [00:05<00:10, 29.14it/s]\u001b[A\n",
            "loss=2.291677236557007 batch_id=149:  32%|███▏      | 149/469 [00:05<00:10, 29.14it/s] \u001b[A\n",
            "loss=2.2932705879211426 batch_id=150:  32%|███▏      | 149/469 [00:05<00:10, 29.14it/s]\u001b[A\n",
            "loss=2.2948625087738037 batch_id=151:  32%|███▏      | 149/469 [00:05<00:10, 29.14it/s]\u001b[A\n",
            "loss=2.2948625087738037 batch_id=151:  32%|███▏      | 152/469 [00:05<00:10, 28.91it/s]\u001b[A\n",
            "loss=2.2900338172912598 batch_id=152:  32%|███▏      | 152/469 [00:05<00:10, 28.91it/s]\u001b[A\n",
            "loss=2.295116662979126 batch_id=153:  32%|███▏      | 152/469 [00:05<00:10, 28.91it/s] \u001b[A\n",
            "loss=2.291334390640259 batch_id=154:  32%|███▏      | 152/469 [00:05<00:10, 28.91it/s]\u001b[A\n",
            "loss=2.291334390640259 batch_id=154:  33%|███▎      | 155/469 [00:05<00:10, 28.70it/s]\u001b[A\n",
            "loss=2.290950059890747 batch_id=155:  33%|███▎      | 155/469 [00:05<00:10, 28.70it/s]\u001b[A\n",
            "loss=2.29148006439209 batch_id=156:  33%|███▎      | 155/469 [00:05<00:10, 28.70it/s] \u001b[A\n",
            "loss=2.290802478790283 batch_id=157:  33%|███▎      | 155/469 [00:05<00:10, 28.70it/s]\u001b[A\n",
            "loss=2.290802478790283 batch_id=157:  34%|███▎      | 158/469 [00:05<00:10, 28.92it/s]\u001b[A\n",
            "loss=2.290637969970703 batch_id=158:  34%|███▎      | 158/469 [00:05<00:10, 28.92it/s]\u001b[A\n",
            "loss=2.2880799770355225 batch_id=159:  34%|███▎      | 158/469 [00:05<00:10, 28.92it/s]\u001b[A\n",
            "loss=2.2926218509674072 batch_id=160:  34%|███▎      | 158/469 [00:05<00:10, 28.92it/s]\u001b[A\n",
            "loss=2.2926218509674072 batch_id=160:  34%|███▍      | 161/469 [00:05<00:10, 28.87it/s]\u001b[A\n",
            "loss=2.2931079864501953 batch_id=161:  34%|███▍      | 161/469 [00:05<00:10, 28.87it/s]\u001b[A\n",
            "loss=2.288090944290161 batch_id=162:  34%|███▍      | 161/469 [00:05<00:10, 28.87it/s] \u001b[A\n",
            "loss=2.2915420532226562 batch_id=163:  34%|███▍      | 161/469 [00:05<00:10, 28.87it/s]\u001b[A\n",
            "loss=2.2915420532226562 batch_id=163:  35%|███▍      | 164/469 [00:05<00:10, 28.33it/s]\u001b[A\n",
            "loss=2.290982484817505 batch_id=164:  35%|███▍      | 164/469 [00:05<00:10, 28.33it/s] \u001b[A\n",
            "loss=2.2921175956726074 batch_id=165:  35%|███▍      | 164/469 [00:05<00:10, 28.33it/s]\u001b[A\n",
            "loss=2.2919421195983887 batch_id=166:  35%|███▍      | 164/469 [00:05<00:10, 28.33it/s]\u001b[A\n",
            "loss=2.2923498153686523 batch_id=167:  35%|███▍      | 164/469 [00:05<00:10, 28.33it/s]\u001b[A\n",
            "loss=2.2923498153686523 batch_id=167:  36%|███▌      | 168/469 [00:05<00:10, 29.34it/s]\u001b[A\n",
            "loss=2.289545774459839 batch_id=168:  36%|███▌      | 168/469 [00:05<00:10, 29.34it/s] \u001b[A\n",
            "loss=2.292107343673706 batch_id=169:  36%|███▌      | 168/469 [00:05<00:10, 29.34it/s]\u001b[A\n",
            "loss=2.2869813442230225 batch_id=170:  36%|███▌      | 168/469 [00:05<00:10, 29.34it/s]\u001b[A\n",
            "loss=2.2869813442230225 batch_id=170:  36%|███▋      | 171/469 [00:05<00:10, 27.93it/s]\u001b[A\n",
            "loss=2.2919769287109375 batch_id=171:  36%|███▋      | 171/469 [00:05<00:10, 27.93it/s]\u001b[A\n",
            "loss=2.291015386581421 batch_id=172:  36%|███▋      | 171/469 [00:05<00:10, 27.93it/s] \u001b[A\n",
            "loss=2.290066957473755 batch_id=173:  36%|███▋      | 171/469 [00:05<00:10, 27.93it/s]\u001b[A\n",
            "loss=2.290066957473755 batch_id=173:  37%|███▋      | 174/469 [00:05<00:10, 28.20it/s]\u001b[A\n",
            "loss=2.2908384799957275 batch_id=174:  37%|███▋      | 174/469 [00:06<00:10, 28.20it/s]\u001b[A\n",
            "loss=2.287947654724121 batch_id=175:  37%|███▋      | 174/469 [00:06<00:10, 28.20it/s] \u001b[A\n",
            "loss=2.2896337509155273 batch_id=176:  37%|███▋      | 174/469 [00:06<00:10, 28.20it/s]\u001b[A\n",
            "loss=2.2891666889190674 batch_id=177:  37%|███▋      | 174/469 [00:06<00:10, 28.20it/s]\u001b[A\n",
            "loss=2.2891666889190674 batch_id=177:  38%|███▊      | 178/469 [00:06<00:10, 28.67it/s]\u001b[A\n",
            "loss=2.286311388015747 batch_id=178:  38%|███▊      | 178/469 [00:06<00:10, 28.67it/s] \u001b[A\n",
            "loss=2.2858047485351562 batch_id=179:  38%|███▊      | 178/469 [00:06<00:10, 28.67it/s]\u001b[A\n",
            "loss=2.288762331008911 batch_id=180:  38%|███▊      | 178/469 [00:06<00:10, 28.67it/s] \u001b[A\n",
            "loss=2.288762331008911 batch_id=180:  39%|███▊      | 181/469 [00:06<00:09, 28.96it/s]\u001b[A\n",
            "loss=2.29086971282959 batch_id=181:  39%|███▊      | 181/469 [00:06<00:09, 28.96it/s] \u001b[A\n",
            "loss=2.288132667541504 batch_id=182:  39%|███▊      | 181/469 [00:06<00:09, 28.96it/s]\u001b[A\n",
            "loss=2.2924540042877197 batch_id=183:  39%|███▊      | 181/469 [00:06<00:09, 28.96it/s]\u001b[A\n",
            "loss=2.2924540042877197 batch_id=183:  39%|███▉      | 184/469 [00:06<00:09, 29.16it/s]\u001b[A\n",
            "loss=2.28741455078125 batch_id=184:  39%|███▉      | 184/469 [00:06<00:09, 29.16it/s]  \u001b[A\n",
            "loss=2.2857601642608643 batch_id=185:  39%|███▉      | 184/469 [00:06<00:09, 29.16it/s]\u001b[A\n",
            "loss=2.285607099533081 batch_id=186:  39%|███▉      | 184/469 [00:06<00:09, 29.16it/s] \u001b[A\n",
            "loss=2.2880945205688477 batch_id=187:  39%|███▉      | 184/469 [00:06<00:09, 29.16it/s]\u001b[A\n",
            "loss=2.2880945205688477 batch_id=187:  40%|████      | 188/469 [00:06<00:09, 30.33it/s]\u001b[A\n",
            "loss=2.2898244857788086 batch_id=188:  40%|████      | 188/469 [00:06<00:09, 30.33it/s]\u001b[A\n",
            "loss=2.2852694988250732 batch_id=189:  40%|████      | 188/469 [00:06<00:09, 30.33it/s]\u001b[A\n",
            "loss=2.290302038192749 batch_id=190:  40%|████      | 188/469 [00:06<00:09, 30.33it/s] \u001b[A\n",
            "loss=2.2897932529449463 batch_id=191:  40%|████      | 188/469 [00:06<00:09, 30.33it/s]\u001b[A\n",
            "loss=2.2897932529449463 batch_id=191:  41%|████      | 192/469 [00:06<00:09, 29.30it/s]\u001b[A\n",
            "loss=2.285423755645752 batch_id=192:  41%|████      | 192/469 [00:06<00:09, 29.30it/s] \u001b[A\n",
            "loss=2.287598133087158 batch_id=193:  41%|████      | 192/469 [00:06<00:09, 29.30it/s]\u001b[A\n",
            "loss=2.2854583263397217 batch_id=194:  41%|████      | 192/469 [00:06<00:09, 29.30it/s]\u001b[A\n",
            "loss=2.2862343788146973 batch_id=195:  41%|████      | 192/469 [00:06<00:09, 29.30it/s]\u001b[A\n",
            "loss=2.2862343788146973 batch_id=195:  42%|████▏     | 196/469 [00:06<00:09, 30.06it/s]\u001b[A\n",
            "loss=2.287609100341797 batch_id=196:  42%|████▏     | 196/469 [00:06<00:09, 30.06it/s] \u001b[A\n",
            "loss=2.285092353820801 batch_id=197:  42%|████▏     | 196/469 [00:06<00:09, 30.06it/s]\u001b[A\n",
            "loss=2.2855403423309326 batch_id=198:  42%|████▏     | 196/469 [00:06<00:09, 30.06it/s]\u001b[A\n",
            "loss=2.2816920280456543 batch_id=199:  42%|████▏     | 196/469 [00:06<00:09, 30.06it/s]\u001b[A\n",
            "loss=2.2816920280456543 batch_id=199:  43%|████▎     | 200/469 [00:06<00:09, 29.38it/s]\u001b[A\n",
            "loss=2.2873716354370117 batch_id=200:  43%|████▎     | 200/469 [00:06<00:09, 29.38it/s]\u001b[A\n",
            "loss=2.2842679023742676 batch_id=201:  43%|████▎     | 200/469 [00:06<00:09, 29.38it/s]\u001b[A\n",
            "loss=2.28792142868042 batch_id=202:  43%|████▎     | 200/469 [00:06<00:09, 29.38it/s]  \u001b[A\n",
            "loss=2.28792142868042 batch_id=202:  43%|████▎     | 203/469 [00:06<00:09, 28.84it/s]\u001b[A\n",
            "loss=2.2842705249786377 batch_id=203:  43%|████▎     | 203/469 [00:06<00:09, 28.84it/s]\u001b[A\n",
            "loss=2.2868831157684326 batch_id=204:  43%|████▎     | 203/469 [00:07<00:09, 28.84it/s]\u001b[A\n",
            "loss=2.283123731613159 batch_id=205:  43%|████▎     | 203/469 [00:07<00:09, 28.84it/s] \u001b[A\n",
            "loss=2.283123731613159 batch_id=205:  44%|████▍     | 206/469 [00:07<00:09, 28.74it/s]\u001b[A\n",
            "loss=2.284276008605957 batch_id=206:  44%|████▍     | 206/469 [00:07<00:09, 28.74it/s]\u001b[A\n",
            "loss=2.2868692874908447 batch_id=207:  44%|████▍     | 206/469 [00:07<00:09, 28.74it/s]\u001b[A\n",
            "loss=2.283328056335449 batch_id=208:  44%|████▍     | 206/469 [00:07<00:09, 28.74it/s] \u001b[A\n",
            "loss=2.285581350326538 batch_id=209:  44%|████▍     | 206/469 [00:07<00:09, 28.74it/s]\u001b[A\n",
            "loss=2.285581350326538 batch_id=209:  45%|████▍     | 210/469 [00:07<00:08, 29.35it/s]\u001b[A\n",
            "loss=2.279244899749756 batch_id=210:  45%|████▍     | 210/469 [00:07<00:08, 29.35it/s]\u001b[A\n",
            "loss=2.28261137008667 batch_id=211:  45%|████▍     | 210/469 [00:07<00:08, 29.35it/s] \u001b[A\n",
            "loss=2.2813775539398193 batch_id=212:  45%|████▍     | 210/469 [00:07<00:08, 29.35it/s]\u001b[A\n",
            "loss=2.2813775539398193 batch_id=212:  45%|████▌     | 213/469 [00:07<00:08, 29.39it/s]\u001b[A\n",
            "loss=2.2800068855285645 batch_id=213:  45%|████▌     | 213/469 [00:07<00:08, 29.39it/s]\u001b[A\n",
            "loss=2.277601957321167 batch_id=214:  45%|████▌     | 213/469 [00:07<00:08, 29.39it/s] \u001b[A\n",
            "loss=2.2791459560394287 batch_id=215:  45%|████▌     | 213/469 [00:07<00:08, 29.39it/s]\u001b[A\n",
            "loss=2.2791459560394287 batch_id=215:  46%|████▌     | 216/469 [00:07<00:08, 29.38it/s]\u001b[A\n",
            "loss=2.2789204120635986 batch_id=216:  46%|████▌     | 216/469 [00:07<00:08, 29.38it/s]\u001b[A\n",
            "loss=2.2821998596191406 batch_id=217:  46%|████▌     | 216/469 [00:07<00:08, 29.38it/s]\u001b[A\n",
            "loss=2.282135009765625 batch_id=218:  46%|████▌     | 216/469 [00:07<00:08, 29.38it/s] \u001b[A\n",
            "loss=2.282135009765625 batch_id=218:  47%|████▋     | 219/469 [00:07<00:08, 28.39it/s]\u001b[A\n",
            "loss=2.2828361988067627 batch_id=219:  47%|████▋     | 219/469 [00:07<00:08, 28.39it/s]\u001b[A\n",
            "loss=2.281221389770508 batch_id=220:  47%|████▋     | 219/469 [00:07<00:08, 28.39it/s] \u001b[A\n",
            "loss=2.284038543701172 batch_id=221:  47%|████▋     | 219/469 [00:07<00:08, 28.39it/s]\u001b[A\n",
            "loss=2.2864768505096436 batch_id=222:  47%|████▋     | 219/469 [00:07<00:08, 28.39it/s]\u001b[A\n",
            "loss=2.2864768505096436 batch_id=222:  48%|████▊     | 223/469 [00:07<00:08, 28.70it/s]\u001b[A\n",
            "loss=2.2865936756134033 batch_id=223:  48%|████▊     | 223/469 [00:07<00:08, 28.70it/s]\u001b[A\n",
            "loss=2.278360366821289 batch_id=224:  48%|████▊     | 223/469 [00:07<00:08, 28.70it/s] \u001b[A\n",
            "loss=2.2796919345855713 batch_id=225:  48%|████▊     | 223/469 [00:07<00:08, 28.70it/s]\u001b[A\n",
            "loss=2.276496410369873 batch_id=226:  48%|████▊     | 223/469 [00:07<00:08, 28.70it/s] \u001b[A\n",
            "loss=2.276496410369873 batch_id=226:  48%|████▊     | 227/469 [00:07<00:08, 29.65it/s]\u001b[A\n",
            "loss=2.278587579727173 batch_id=227:  48%|████▊     | 227/469 [00:07<00:08, 29.65it/s]\u001b[A\n",
            "loss=2.2794530391693115 batch_id=228:  48%|████▊     | 227/469 [00:07<00:08, 29.65it/s]\u001b[A\n",
            "loss=2.284152030944824 batch_id=229:  48%|████▊     | 227/469 [00:07<00:08, 29.65it/s] \u001b[A\n",
            "loss=2.2788896560668945 batch_id=230:  48%|████▊     | 227/469 [00:07<00:08, 29.65it/s]\u001b[A\n",
            "loss=2.2788896560668945 batch_id=230:  49%|████▉     | 231/469 [00:07<00:07, 30.30it/s]\u001b[A\n",
            "loss=2.2750933170318604 batch_id=231:  49%|████▉     | 231/469 [00:07<00:07, 30.30it/s]\u001b[A\n",
            "loss=2.2838261127471924 batch_id=232:  49%|████▉     | 231/469 [00:07<00:07, 30.30it/s]\u001b[A\n",
            "loss=2.2769572734832764 batch_id=233:  49%|████▉     | 231/469 [00:07<00:07, 30.30it/s]\u001b[A\n",
            "loss=2.279240608215332 batch_id=234:  49%|████▉     | 231/469 [00:08<00:07, 30.30it/s] \u001b[A\n",
            "loss=2.279240608215332 batch_id=234:  50%|█████     | 235/469 [00:08<00:07, 30.04it/s]\u001b[A\n",
            "loss=2.272897481918335 batch_id=235:  50%|█████     | 235/469 [00:08<00:07, 30.04it/s]\u001b[A\n",
            "loss=2.280705690383911 batch_id=236:  50%|█████     | 235/469 [00:08<00:07, 30.04it/s]\u001b[A\n",
            "loss=2.2736546993255615 batch_id=237:  50%|█████     | 235/469 [00:08<00:07, 30.04it/s]\u001b[A\n",
            "loss=2.278076648712158 batch_id=238:  50%|█████     | 235/469 [00:08<00:07, 30.04it/s] \u001b[A\n",
            "loss=2.278076648712158 batch_id=238:  51%|█████     | 239/469 [00:08<00:07, 29.47it/s]\u001b[A\n",
            "loss=2.275285482406616 batch_id=239:  51%|█████     | 239/469 [00:08<00:07, 29.47it/s]\u001b[A\n",
            "loss=2.277554988861084 batch_id=240:  51%|█████     | 239/469 [00:08<00:07, 29.47it/s]\u001b[A\n",
            "loss=2.2751221656799316 batch_id=241:  51%|█████     | 239/469 [00:08<00:07, 29.47it/s]\u001b[A\n",
            "loss=2.2751221656799316 batch_id=241:  52%|█████▏    | 242/469 [00:08<00:07, 28.56it/s]\u001b[A\n",
            "loss=2.276186227798462 batch_id=242:  52%|█████▏    | 242/469 [00:08<00:07, 28.56it/s] \u001b[A\n",
            "loss=2.278226852416992 batch_id=243:  52%|█████▏    | 242/469 [00:08<00:07, 28.56it/s]\u001b[A\n",
            "loss=2.2720627784729004 batch_id=244:  52%|█████▏    | 242/469 [00:08<00:07, 28.56it/s]\u001b[A\n",
            "loss=2.2741689682006836 batch_id=245:  52%|█████▏    | 242/469 [00:08<00:07, 28.56it/s]\u001b[A\n",
            "loss=2.2741689682006836 batch_id=245:  52%|█████▏    | 246/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.270676374435425 batch_id=246:  52%|█████▏    | 246/469 [00:08<00:07, 29.59it/s] \u001b[A\n",
            "loss=2.271817684173584 batch_id=247:  52%|█████▏    | 246/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2805886268615723 batch_id=248:  52%|█████▏    | 246/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2705113887786865 batch_id=249:  52%|█████▏    | 246/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2705113887786865 batch_id=249:  53%|█████▎    | 250/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2769200801849365 batch_id=250:  53%|█████▎    | 250/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2734079360961914 batch_id=251:  53%|█████▎    | 250/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2687010765075684 batch_id=252:  53%|█████▎    | 250/469 [00:08<00:07, 29.59it/s]\u001b[A\n",
            "loss=2.2687010765075684 batch_id=252:  54%|█████▍    | 253/469 [00:08<00:07, 29.31it/s]\u001b[A\n",
            "loss=2.2698898315429688 batch_id=253:  54%|█████▍    | 253/469 [00:08<00:07, 29.31it/s]\u001b[A\n",
            "loss=2.273350715637207 batch_id=254:  54%|█████▍    | 253/469 [00:08<00:07, 29.31it/s] \u001b[A\n",
            "loss=2.2714340686798096 batch_id=255:  54%|█████▍    | 253/469 [00:08<00:07, 29.31it/s]\u001b[A\n",
            "loss=2.2625892162323 batch_id=256:  54%|█████▍    | 253/469 [00:08<00:07, 29.31it/s]   \u001b[A\n",
            "loss=2.2625892162323 batch_id=256:  55%|█████▍    | 257/469 [00:08<00:07, 29.89it/s]\u001b[A\n",
            "loss=2.2742819786071777 batch_id=257:  55%|█████▍    | 257/469 [00:08<00:07, 29.89it/s]\u001b[A\n",
            "loss=2.2750701904296875 batch_id=258:  55%|█████▍    | 257/469 [00:08<00:07, 29.89it/s]\u001b[A\n",
            "loss=2.258723258972168 batch_id=259:  55%|█████▍    | 257/469 [00:08<00:07, 29.89it/s] \u001b[A\n",
            "loss=2.2733147144317627 batch_id=260:  55%|█████▍    | 257/469 [00:08<00:07, 29.89it/s]\u001b[A\n",
            "loss=2.2733147144317627 batch_id=260:  56%|█████▌    | 261/469 [00:08<00:06, 30.06it/s]\u001b[A\n",
            "loss=2.2680344581604004 batch_id=261:  56%|█████▌    | 261/469 [00:08<00:06, 30.06it/s]\u001b[A\n",
            "loss=2.258732557296753 batch_id=262:  56%|█████▌    | 261/469 [00:08<00:06, 30.06it/s] \u001b[A\n",
            "loss=2.263031482696533 batch_id=263:  56%|█████▌    | 261/469 [00:08<00:06, 30.06it/s]\u001b[A\n",
            "loss=2.27663516998291 batch_id=264:  56%|█████▌    | 261/469 [00:09<00:06, 30.06it/s] \u001b[A\n",
            "loss=2.27663516998291 batch_id=264:  57%|█████▋    | 265/469 [00:09<00:06, 30.45it/s]\u001b[A\n",
            "loss=2.270798683166504 batch_id=265:  57%|█████▋    | 265/469 [00:09<00:06, 30.45it/s]\u001b[A\n",
            "loss=2.2689459323883057 batch_id=266:  57%|█████▋    | 265/469 [00:09<00:06, 30.45it/s]\u001b[A\n",
            "loss=2.2608463764190674 batch_id=267:  57%|█████▋    | 265/469 [00:09<00:06, 30.45it/s]\u001b[A\n",
            "loss=2.2696568965911865 batch_id=268:  57%|█████▋    | 265/469 [00:09<00:06, 30.45it/s]\u001b[A\n",
            "loss=2.2696568965911865 batch_id=268:  57%|█████▋    | 269/469 [00:09<00:06, 29.99it/s]\u001b[A\n",
            "loss=2.25716233253479 batch_id=269:  57%|█████▋    | 269/469 [00:09<00:06, 29.99it/s]  \u001b[A\n",
            "loss=2.2571051120758057 batch_id=270:  57%|█████▋    | 269/469 [00:09<00:06, 29.99it/s]\u001b[A\n",
            "loss=2.267045259475708 batch_id=271:  57%|█████▋    | 269/469 [00:09<00:06, 29.99it/s] \u001b[A\n",
            "loss=2.25984525680542 batch_id=272:  57%|█████▋    | 269/469 [00:09<00:06, 29.99it/s] \u001b[A\n",
            "loss=2.25984525680542 batch_id=272:  58%|█████▊    | 273/469 [00:09<00:06, 31.11it/s]\u001b[A\n",
            "loss=2.258472204208374 batch_id=273:  58%|█████▊    | 273/469 [00:09<00:06, 31.11it/s]\u001b[A\n",
            "loss=2.2588839530944824 batch_id=274:  58%|█████▊    | 273/469 [00:09<00:06, 31.11it/s]\u001b[A\n",
            "loss=2.261042594909668 batch_id=275:  58%|█████▊    | 273/469 [00:09<00:06, 31.11it/s] \u001b[A\n",
            "loss=2.258756399154663 batch_id=276:  58%|█████▊    | 273/469 [00:09<00:06, 31.11it/s]\u001b[A\n",
            "loss=2.258756399154663 batch_id=276:  59%|█████▉    | 277/469 [00:09<00:06, 30.74it/s]\u001b[A\n",
            "loss=2.2600574493408203 batch_id=277:  59%|█████▉    | 277/469 [00:09<00:06, 30.74it/s]\u001b[A\n",
            "loss=2.265549659729004 batch_id=278:  59%|█████▉    | 277/469 [00:09<00:06, 30.74it/s] \u001b[A\n",
            "loss=2.258662700653076 batch_id=279:  59%|█████▉    | 277/469 [00:09<00:06, 30.74it/s]\u001b[A\n",
            "loss=2.252525568008423 batch_id=280:  59%|█████▉    | 277/469 [00:09<00:06, 30.74it/s]\u001b[A\n",
            "loss=2.252525568008423 batch_id=280:  60%|█████▉    | 281/469 [00:09<00:06, 30.11it/s]\u001b[A\n",
            "loss=2.2607181072235107 batch_id=281:  60%|█████▉    | 281/469 [00:09<00:06, 30.11it/s]\u001b[A\n",
            "loss=2.2560298442840576 batch_id=282:  60%|█████▉    | 281/469 [00:09<00:06, 30.11it/s]\u001b[A\n",
            "loss=2.2526261806488037 batch_id=283:  60%|█████▉    | 281/469 [00:09<00:06, 30.11it/s]\u001b[A\n",
            "loss=2.243985891342163 batch_id=284:  60%|█████▉    | 281/469 [00:09<00:06, 30.11it/s] \u001b[A\n",
            "loss=2.243985891342163 batch_id=284:  61%|██████    | 285/469 [00:09<00:05, 30.75it/s]\u001b[A\n",
            "loss=2.258782386779785 batch_id=285:  61%|██████    | 285/469 [00:09<00:05, 30.75it/s]\u001b[A\n",
            "loss=2.256514310836792 batch_id=286:  61%|██████    | 285/469 [00:09<00:05, 30.75it/s]\u001b[A\n",
            "loss=2.253814220428467 batch_id=287:  61%|██████    | 285/469 [00:09<00:05, 30.75it/s]\u001b[A\n",
            "loss=2.249072313308716 batch_id=288:  61%|██████    | 285/469 [00:09<00:05, 30.75it/s]\u001b[A\n",
            "loss=2.249072313308716 batch_id=288:  62%|██████▏   | 289/469 [00:09<00:05, 30.95it/s]\u001b[A\n",
            "loss=2.259920835494995 batch_id=289:  62%|██████▏   | 289/469 [00:09<00:05, 30.95it/s]\u001b[A\n",
            "loss=2.257336378097534 batch_id=290:  62%|██████▏   | 289/469 [00:09<00:05, 30.95it/s]\u001b[A\n",
            "loss=2.2562196254730225 batch_id=291:  62%|██████▏   | 289/469 [00:09<00:05, 30.95it/s]\u001b[A\n",
            "loss=2.2406911849975586 batch_id=292:  62%|██████▏   | 289/469 [00:09<00:05, 30.95it/s]\u001b[A\n",
            "loss=2.2406911849975586 batch_id=292:  62%|██████▏   | 293/469 [00:09<00:05, 30.60it/s]\u001b[A\n",
            "loss=2.2345519065856934 batch_id=293:  62%|██████▏   | 293/469 [00:09<00:05, 30.60it/s]\u001b[A\n",
            "loss=2.2407679557800293 batch_id=294:  62%|██████▏   | 293/469 [00:10<00:05, 30.60it/s]\u001b[A\n",
            "loss=2.2479467391967773 batch_id=295:  62%|██████▏   | 293/469 [00:10<00:05, 30.60it/s]\u001b[A\n",
            "loss=2.246755599975586 batch_id=296:  62%|██████▏   | 293/469 [00:10<00:05, 30.60it/s] \u001b[A\n",
            "loss=2.246755599975586 batch_id=296:  63%|██████▎   | 297/469 [00:10<00:05, 30.38it/s]\u001b[A\n",
            "loss=2.2454993724823 batch_id=297:  63%|██████▎   | 297/469 [00:10<00:05, 30.38it/s]  \u001b[A\n",
            "loss=2.2323381900787354 batch_id=298:  63%|██████▎   | 297/469 [00:10<00:05, 30.38it/s]\u001b[A\n",
            "loss=2.24554705619812 batch_id=299:  63%|██████▎   | 297/469 [00:10<00:05, 30.38it/s]  \u001b[A\n",
            "loss=2.2342050075531006 batch_id=300:  63%|██████▎   | 297/469 [00:10<00:05, 30.38it/s]\u001b[A\n",
            "loss=2.2342050075531006 batch_id=300:  64%|██████▍   | 301/469 [00:10<00:05, 30.30it/s]\u001b[A\n",
            "loss=2.2433276176452637 batch_id=301:  64%|██████▍   | 301/469 [00:10<00:05, 30.30it/s]\u001b[A\n",
            "loss=2.2498269081115723 batch_id=302:  64%|██████▍   | 301/469 [00:10<00:05, 30.30it/s]\u001b[A\n",
            "loss=2.2329108715057373 batch_id=303:  64%|██████▍   | 301/469 [00:10<00:05, 30.30it/s]\u001b[A\n",
            "loss=2.23380708694458 batch_id=304:  64%|██████▍   | 301/469 [00:10<00:05, 30.30it/s]  \u001b[A\n",
            "loss=2.23380708694458 batch_id=304:  65%|██████▌   | 305/469 [00:10<00:05, 30.00it/s]\u001b[A\n",
            "loss=2.22849178314209 batch_id=305:  65%|██████▌   | 305/469 [00:10<00:05, 30.00it/s]\u001b[A\n",
            "loss=2.2530555725097656 batch_id=306:  65%|██████▌   | 305/469 [00:10<00:05, 30.00it/s]\u001b[A\n",
            "loss=2.209777355194092 batch_id=307:  65%|██████▌   | 305/469 [00:10<00:05, 30.00it/s] \u001b[A\n",
            "loss=2.2392072677612305 batch_id=308:  65%|██████▌   | 305/469 [00:10<00:05, 30.00it/s]\u001b[A\n",
            "loss=2.2392072677612305 batch_id=308:  66%|██████▌   | 309/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.2302439212799072 batch_id=309:  66%|██████▌   | 309/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.2276666164398193 batch_id=310:  66%|██████▌   | 309/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.2397100925445557 batch_id=311:  66%|██████▌   | 309/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.2397100925445557 batch_id=311:  67%|██████▋   | 312/469 [00:10<00:05, 29.25it/s]\u001b[A\n",
            "loss=2.2187485694885254 batch_id=312:  67%|██████▋   | 312/469 [00:10<00:05, 29.25it/s]\u001b[A\n",
            "loss=2.240245819091797 batch_id=313:  67%|██████▋   | 312/469 [00:10<00:05, 29.25it/s] \u001b[A\n",
            "loss=2.2359213829040527 batch_id=314:  67%|██████▋   | 312/469 [00:10<00:05, 29.25it/s]\u001b[A\n",
            "loss=2.2020370960235596 batch_id=315:  67%|██████▋   | 312/469 [00:10<00:05, 29.25it/s]\u001b[A\n",
            "loss=2.2020370960235596 batch_id=315:  67%|██████▋   | 316/469 [00:10<00:05, 30.24it/s]\u001b[A\n",
            "loss=2.220029354095459 batch_id=316:  67%|██████▋   | 316/469 [00:10<00:05, 30.24it/s] \u001b[A\n",
            "loss=2.2114858627319336 batch_id=317:  67%|██████▋   | 316/469 [00:10<00:05, 30.24it/s]\u001b[A\n",
            "loss=2.2138473987579346 batch_id=318:  67%|██████▋   | 316/469 [00:10<00:05, 30.24it/s]\u001b[A\n",
            "loss=2.2003307342529297 batch_id=319:  67%|██████▋   | 316/469 [00:10<00:05, 30.24it/s]\u001b[A\n",
            "loss=2.2003307342529297 batch_id=319:  68%|██████▊   | 320/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.20457124710083 batch_id=320:  68%|██████▊   | 320/469 [00:10<00:05, 29.76it/s]  \u001b[A\n",
            "loss=2.1970980167388916 batch_id=321:  68%|██████▊   | 320/469 [00:10<00:05, 29.76it/s]\u001b[A\n",
            "loss=2.215420961380005 batch_id=322:  68%|██████▊   | 320/469 [00:10<00:05, 29.76it/s] \u001b[A\n",
            "loss=2.215420961380005 batch_id=322:  69%|██████▉   | 323/469 [00:10<00:04, 29.51it/s]\u001b[A\n",
            "loss=2.203554630279541 batch_id=323:  69%|██████▉   | 323/469 [00:10<00:04, 29.51it/s]\u001b[A\n",
            "loss=2.1855227947235107 batch_id=324:  69%|██████▉   | 323/469 [00:11<00:04, 29.51it/s]\u001b[A\n",
            "loss=2.2091147899627686 batch_id=325:  69%|██████▉   | 323/469 [00:11<00:04, 29.51it/s]\u001b[A\n",
            "loss=2.2091147899627686 batch_id=325:  70%|██████▉   | 326/469 [00:11<00:04, 29.59it/s]\u001b[A\n",
            "loss=2.1940886974334717 batch_id=326:  70%|██████▉   | 326/469 [00:11<00:04, 29.59it/s]\u001b[A\n",
            "loss=2.2114124298095703 batch_id=327:  70%|██████▉   | 326/469 [00:11<00:04, 29.59it/s]\u001b[A\n",
            "loss=2.184396982192993 batch_id=328:  70%|██████▉   | 326/469 [00:11<00:04, 29.59it/s] \u001b[A\n",
            "loss=2.2092347145080566 batch_id=329:  70%|██████▉   | 326/469 [00:11<00:04, 29.59it/s]\u001b[A\n",
            "loss=2.2092347145080566 batch_id=329:  70%|███████   | 330/469 [00:11<00:04, 29.91it/s]\u001b[A\n",
            "loss=2.1911838054656982 batch_id=330:  70%|███████   | 330/469 [00:11<00:04, 29.91it/s]\u001b[A\n",
            "loss=2.1919195652008057 batch_id=331:  70%|███████   | 330/469 [00:11<00:04, 29.91it/s]\u001b[A\n",
            "loss=2.1533985137939453 batch_id=332:  70%|███████   | 330/469 [00:11<00:04, 29.91it/s]\u001b[A\n",
            "loss=2.18453311920166 batch_id=333:  70%|███████   | 330/469 [00:11<00:04, 29.91it/s]  \u001b[A\n",
            "loss=2.18453311920166 batch_id=333:  71%|███████   | 334/469 [00:11<00:04, 31.36it/s]\u001b[A\n",
            "loss=2.179091215133667 batch_id=334:  71%|███████   | 334/469 [00:11<00:04, 31.36it/s]\u001b[A\n",
            "loss=2.211204767227173 batch_id=335:  71%|███████   | 334/469 [00:11<00:04, 31.36it/s]\u001b[A\n",
            "loss=2.163945198059082 batch_id=336:  71%|███████   | 334/469 [00:11<00:04, 31.36it/s]\u001b[A\n",
            "loss=2.1857213973999023 batch_id=337:  71%|███████   | 334/469 [00:11<00:04, 31.36it/s]\u001b[A\n",
            "loss=2.1857213973999023 batch_id=337:  72%|███████▏  | 338/469 [00:11<00:04, 31.09it/s]\u001b[A\n",
            "loss=2.1837897300720215 batch_id=338:  72%|███████▏  | 338/469 [00:11<00:04, 31.09it/s]\u001b[A\n",
            "loss=2.1563549041748047 batch_id=339:  72%|███████▏  | 338/469 [00:11<00:04, 31.09it/s]\u001b[A\n",
            "loss=2.139725923538208 batch_id=340:  72%|███████▏  | 338/469 [00:11<00:04, 31.09it/s] \u001b[A\n",
            "loss=2.1527044773101807 batch_id=341:  72%|███████▏  | 338/469 [00:11<00:04, 31.09it/s]\u001b[A\n",
            "loss=2.1527044773101807 batch_id=341:  73%|███████▎  | 342/469 [00:11<00:04, 30.52it/s]\u001b[A\n",
            "loss=2.151576519012451 batch_id=342:  73%|███████▎  | 342/469 [00:11<00:04, 30.52it/s] \u001b[A\n",
            "loss=2.1132748126983643 batch_id=343:  73%|███████▎  | 342/469 [00:11<00:04, 30.52it/s]\u001b[A\n",
            "loss=2.101897954940796 batch_id=344:  73%|███████▎  | 342/469 [00:11<00:04, 30.52it/s] \u001b[A\n",
            "loss=2.1591849327087402 batch_id=345:  73%|███████▎  | 342/469 [00:11<00:04, 30.52it/s]\u001b[A\n",
            "loss=2.1591849327087402 batch_id=345:  74%|███████▍  | 346/469 [00:11<00:04, 29.60it/s]\u001b[A\n",
            "loss=2.1570932865142822 batch_id=346:  74%|███████▍  | 346/469 [00:11<00:04, 29.60it/s]\u001b[A\n",
            "loss=2.099241018295288 batch_id=347:  74%|███████▍  | 346/469 [00:11<00:04, 29.60it/s] \u001b[A\n",
            "loss=2.1497840881347656 batch_id=348:  74%|███████▍  | 346/469 [00:11<00:04, 29.60it/s]\u001b[A\n",
            "loss=2.1497840881347656 batch_id=348:  74%|███████▍  | 349/469 [00:11<00:04, 29.70it/s]\u001b[A\n",
            "loss=2.1272077560424805 batch_id=349:  74%|███████▍  | 349/469 [00:11<00:04, 29.70it/s]\u001b[A\n",
            "loss=2.0728442668914795 batch_id=350:  74%|███████▍  | 349/469 [00:11<00:04, 29.70it/s]\u001b[A\n",
            "loss=2.136751174926758 batch_id=351:  74%|███████▍  | 349/469 [00:11<00:04, 29.70it/s] \u001b[A\n",
            "loss=2.136751174926758 batch_id=351:  75%|███████▌  | 352/469 [00:11<00:03, 29.78it/s]\u001b[A\n",
            "loss=2.116159200668335 batch_id=352:  75%|███████▌  | 352/469 [00:11<00:03, 29.78it/s]\u001b[A\n",
            "loss=2.1153595447540283 batch_id=353:  75%|███████▌  | 352/469 [00:11<00:03, 29.78it/s]\u001b[A\n",
            "loss=2.0890321731567383 batch_id=354:  75%|███████▌  | 352/469 [00:12<00:03, 29.78it/s]\u001b[A\n",
            "loss=2.0890321731567383 batch_id=354:  76%|███████▌  | 355/469 [00:12<00:03, 29.05it/s]\u001b[A\n",
            "loss=2.0613925457000732 batch_id=355:  76%|███████▌  | 355/469 [00:12<00:03, 29.05it/s]\u001b[A\n",
            "loss=2.087275981903076 batch_id=356:  76%|███████▌  | 355/469 [00:12<00:03, 29.05it/s] \u001b[A\n",
            "loss=2.103839874267578 batch_id=357:  76%|███████▌  | 355/469 [00:12<00:03, 29.05it/s]\u001b[A\n",
            "loss=2.103839874267578 batch_id=357:  76%|███████▋  | 358/469 [00:12<00:03, 29.31it/s]\u001b[A\n",
            "loss=2.0643935203552246 batch_id=358:  76%|███████▋  | 358/469 [00:12<00:03, 29.31it/s]\u001b[A\n",
            "loss=2.1048295497894287 batch_id=359:  76%|███████▋  | 358/469 [00:12<00:03, 29.31it/s]\u001b[A\n",
            "loss=2.0615200996398926 batch_id=360:  76%|███████▋  | 358/469 [00:12<00:03, 29.31it/s]\u001b[A\n",
            "loss=2.0615200996398926 batch_id=360:  77%|███████▋  | 361/469 [00:12<00:03, 29.38it/s]\u001b[A\n",
            "loss=2.047431230545044 batch_id=361:  77%|███████▋  | 361/469 [00:12<00:03, 29.38it/s] \u001b[A\n",
            "loss=2.01261830329895 batch_id=362:  77%|███████▋  | 361/469 [00:12<00:03, 29.38it/s] \u001b[A\n",
            "loss=2.0534415245056152 batch_id=363:  77%|███████▋  | 361/469 [00:12<00:03, 29.38it/s]\u001b[A\n",
            "loss=2.0534415245056152 batch_id=363:  78%|███████▊  | 364/469 [00:12<00:03, 29.53it/s]\u001b[A\n",
            "loss=2.020888090133667 batch_id=364:  78%|███████▊  | 364/469 [00:12<00:03, 29.53it/s] \u001b[A\n",
            "loss=2.0247642993927 batch_id=365:  78%|███████▊  | 364/469 [00:12<00:03, 29.53it/s]  \u001b[A\n",
            "loss=2.0562286376953125 batch_id=366:  78%|███████▊  | 364/469 [00:12<00:03, 29.53it/s]\u001b[A\n",
            "loss=1.899861454963684 batch_id=367:  78%|███████▊  | 364/469 [00:12<00:03, 29.53it/s] \u001b[A\n",
            "loss=1.899861454963684 batch_id=367:  78%|███████▊  | 368/469 [00:12<00:03, 29.98it/s]\u001b[A\n",
            "loss=2.0131776332855225 batch_id=368:  78%|███████▊  | 368/469 [00:12<00:03, 29.98it/s]\u001b[A\n",
            "loss=1.9633666276931763 batch_id=369:  78%|███████▊  | 368/469 [00:12<00:03, 29.98it/s]\u001b[A\n",
            "loss=1.9726834297180176 batch_id=370:  78%|███████▊  | 368/469 [00:12<00:03, 29.98it/s]\u001b[A\n",
            "loss=1.890127420425415 batch_id=371:  78%|███████▊  | 368/469 [00:12<00:03, 29.98it/s] \u001b[A\n",
            "loss=1.890127420425415 batch_id=371:  79%|███████▉  | 372/469 [00:12<00:03, 30.48it/s]\u001b[A\n",
            "loss=1.9940428733825684 batch_id=372:  79%|███████▉  | 372/469 [00:12<00:03, 30.48it/s]\u001b[A\n",
            "loss=1.8535408973693848 batch_id=373:  79%|███████▉  | 372/469 [00:12<00:03, 30.48it/s]\u001b[A\n",
            "loss=1.9231053590774536 batch_id=374:  79%|███████▉  | 372/469 [00:12<00:03, 30.48it/s]\u001b[A\n",
            "loss=1.9134215116500854 batch_id=375:  79%|███████▉  | 372/469 [00:12<00:03, 30.48it/s]\u001b[A\n",
            "loss=1.9134215116500854 batch_id=375:  80%|████████  | 376/469 [00:12<00:03, 30.39it/s]\u001b[A\n",
            "loss=1.7777667045593262 batch_id=376:  80%|████████  | 376/469 [00:12<00:03, 30.39it/s]\u001b[A\n",
            "loss=1.9408832788467407 batch_id=377:  80%|████████  | 376/469 [00:12<00:03, 30.39it/s]\u001b[A\n",
            "loss=1.8989027738571167 batch_id=378:  80%|████████  | 376/469 [00:12<00:03, 30.39it/s]\u001b[A\n",
            "loss=1.877213716506958 batch_id=379:  80%|████████  | 376/469 [00:12<00:03, 30.39it/s] \u001b[A\n",
            "loss=1.877213716506958 batch_id=379:  81%|████████  | 380/469 [00:12<00:02, 30.45it/s]\u001b[A\n",
            "loss=1.6746188402175903 batch_id=380:  81%|████████  | 380/469 [00:12<00:02, 30.45it/s]\u001b[A\n",
            "loss=1.802754521369934 batch_id=381:  81%|████████  | 380/469 [00:12<00:02, 30.45it/s] \u001b[A\n",
            "loss=1.7857862710952759 batch_id=382:  81%|████████  | 380/469 [00:12<00:02, 30.45it/s]\u001b[A\n",
            "loss=1.648882269859314 batch_id=383:  81%|████████  | 380/469 [00:12<00:02, 30.45it/s] \u001b[A\n",
            "loss=1.648882269859314 batch_id=383:  82%|████████▏ | 384/469 [00:12<00:02, 30.30it/s]\u001b[A\n",
            "loss=1.7970986366271973 batch_id=384:  82%|████████▏ | 384/469 [00:13<00:02, 30.30it/s]\u001b[A\n",
            "loss=1.7416584491729736 batch_id=385:  82%|████████▏ | 384/469 [00:13<00:02, 30.30it/s]\u001b[A\n",
            "loss=1.756928563117981 batch_id=386:  82%|████████▏ | 384/469 [00:13<00:02, 30.30it/s] \u001b[A\n",
            "loss=1.6098980903625488 batch_id=387:  82%|████████▏ | 384/469 [00:13<00:02, 30.30it/s]\u001b[A\n",
            "loss=1.6098980903625488 batch_id=387:  83%|████████▎ | 388/469 [00:13<00:02, 29.44it/s]\u001b[A\n",
            "loss=1.667758584022522 batch_id=388:  83%|████████▎ | 388/469 [00:13<00:02, 29.44it/s] \u001b[A\n",
            "loss=1.710442066192627 batch_id=389:  83%|████████▎ | 388/469 [00:13<00:02, 29.44it/s]\u001b[A\n",
            "loss=1.667323350906372 batch_id=390:  83%|████████▎ | 388/469 [00:13<00:02, 29.44it/s]\u001b[A\n",
            "loss=1.667323350906372 batch_id=390:  83%|████████▎ | 391/469 [00:13<00:02, 28.00it/s]\u001b[A\n",
            "loss=1.6479414701461792 batch_id=391:  83%|████████▎ | 391/469 [00:13<00:02, 28.00it/s]\u001b[A\n",
            "loss=1.6284832954406738 batch_id=392:  83%|████████▎ | 391/469 [00:13<00:02, 28.00it/s]\u001b[A\n",
            "loss=1.5049718618392944 batch_id=393:  83%|████████▎ | 391/469 [00:13<00:02, 28.00it/s]\u001b[A\n",
            "loss=1.5049718618392944 batch_id=393:  84%|████████▍ | 394/469 [00:13<00:02, 28.42it/s]\u001b[A\n",
            "loss=1.593160629272461 batch_id=394:  84%|████████▍ | 394/469 [00:13<00:02, 28.42it/s] \u001b[A\n",
            "loss=1.6117594242095947 batch_id=395:  84%|████████▍ | 394/469 [00:13<00:02, 28.42it/s]\u001b[A\n",
            "loss=1.6074274778366089 batch_id=396:  84%|████████▍ | 394/469 [00:13<00:02, 28.42it/s]\u001b[A\n",
            "loss=1.5597971677780151 batch_id=397:  84%|████████▍ | 394/469 [00:13<00:02, 28.42it/s]\u001b[A\n",
            "loss=1.5597971677780151 batch_id=397:  85%|████████▍ | 398/469 [00:13<00:02, 29.30it/s]\u001b[A\n",
            "loss=1.5585639476776123 batch_id=398:  85%|████████▍ | 398/469 [00:13<00:02, 29.30it/s]\u001b[A\n",
            "loss=1.5088762044906616 batch_id=399:  85%|████████▍ | 398/469 [00:13<00:02, 29.30it/s]\u001b[A\n",
            "loss=1.4891607761383057 batch_id=400:  85%|████████▍ | 398/469 [00:13<00:02, 29.30it/s]\u001b[A\n",
            "loss=1.506912112236023 batch_id=401:  85%|████████▍ | 398/469 [00:13<00:02, 29.30it/s] \u001b[A\n",
            "loss=1.506912112236023 batch_id=401:  86%|████████▌ | 402/469 [00:13<00:02, 29.89it/s]\u001b[A\n",
            "loss=1.3709468841552734 batch_id=402:  86%|████████▌ | 402/469 [00:13<00:02, 29.89it/s]\u001b[A\n",
            "loss=1.386237621307373 batch_id=403:  86%|████████▌ | 402/469 [00:13<00:02, 29.89it/s] \u001b[A\n",
            "loss=1.3701790571212769 batch_id=404:  86%|████████▌ | 402/469 [00:13<00:02, 29.89it/s]\u001b[A\n",
            "loss=1.3952034711837769 batch_id=405:  86%|████████▌ | 402/469 [00:13<00:02, 29.89it/s]\u001b[A\n",
            "loss=1.3952034711837769 batch_id=405:  87%|████████▋ | 406/469 [00:13<00:02, 29.85it/s]\u001b[A\n",
            "loss=1.2943881750106812 batch_id=406:  87%|████████▋ | 406/469 [00:13<00:02, 29.85it/s]\u001b[A\n",
            "loss=1.4861795902252197 batch_id=407:  87%|████████▋ | 406/469 [00:13<00:02, 29.85it/s]\u001b[A\n",
            "loss=1.3005092144012451 batch_id=408:  87%|████████▋ | 406/469 [00:13<00:02, 29.85it/s]\u001b[A\n",
            "loss=1.3005092144012451 batch_id=408:  87%|████████▋ | 409/469 [00:13<00:02, 28.79it/s]\u001b[A\n",
            "loss=1.3160157203674316 batch_id=409:  87%|████████▋ | 409/469 [00:13<00:02, 28.79it/s]\u001b[A\n",
            "loss=1.5609537363052368 batch_id=410:  87%|████████▋ | 409/469 [00:13<00:02, 28.79it/s]\u001b[A\n",
            "loss=1.2459787130355835 batch_id=411:  87%|████████▋ | 409/469 [00:13<00:02, 28.79it/s]\u001b[A\n",
            "loss=1.3335425853729248 batch_id=412:  87%|████████▋ | 409/469 [00:13<00:02, 28.79it/s]\u001b[A\n",
            "loss=1.3335425853729248 batch_id=412:  88%|████████▊ | 413/469 [00:13<00:01, 30.08it/s]\u001b[A\n",
            "loss=1.3613488674163818 batch_id=413:  88%|████████▊ | 413/469 [00:13<00:01, 30.08it/s]\u001b[A\n",
            "loss=1.3959107398986816 batch_id=414:  88%|████████▊ | 413/469 [00:14<00:01, 30.08it/s]\u001b[A\n",
            "loss=1.260262131690979 batch_id=415:  88%|████████▊ | 413/469 [00:14<00:01, 30.08it/s] \u001b[A\n",
            "loss=1.3099181652069092 batch_id=416:  88%|████████▊ | 413/469 [00:14<00:01, 30.08it/s]\u001b[A\n",
            "loss=1.3099181652069092 batch_id=416:  89%|████████▉ | 417/469 [00:14<00:01, 29.77it/s]\u001b[A\n",
            "loss=1.3140909671783447 batch_id=417:  89%|████████▉ | 417/469 [00:14<00:01, 29.77it/s]\u001b[A\n",
            "loss=1.2986528873443604 batch_id=418:  89%|████████▉ | 417/469 [00:14<00:01, 29.77it/s]\u001b[A\n",
            "loss=1.1238044500350952 batch_id=419:  89%|████████▉ | 417/469 [00:14<00:01, 29.77it/s]\u001b[A\n",
            "loss=1.1238044500350952 batch_id=419:  90%|████████▉ | 420/469 [00:14<00:01, 29.55it/s]\u001b[A\n",
            "loss=1.409066081047058 batch_id=420:  90%|████████▉ | 420/469 [00:14<00:01, 29.55it/s] \u001b[A\n",
            "loss=1.3096935749053955 batch_id=421:  90%|████████▉ | 420/469 [00:14<00:01, 29.55it/s]\u001b[A\n",
            "loss=1.1808196306228638 batch_id=422:  90%|████████▉ | 420/469 [00:14<00:01, 29.55it/s]\u001b[A\n",
            "loss=1.1808196306228638 batch_id=422:  90%|█████████ | 423/469 [00:14<00:01, 27.94it/s]\u001b[A\n",
            "loss=1.1353535652160645 batch_id=423:  90%|█████████ | 423/469 [00:14<00:01, 27.94it/s]\u001b[A\n",
            "loss=1.224499225616455 batch_id=424:  90%|█████████ | 423/469 [00:14<00:01, 27.94it/s] \u001b[A\n",
            "loss=1.280186653137207 batch_id=425:  90%|█████████ | 423/469 [00:14<00:01, 27.94it/s]\u001b[A\n",
            "loss=1.280186653137207 batch_id=425:  91%|█████████ | 426/469 [00:14<00:01, 27.83it/s]\u001b[A\n",
            "loss=1.0564591884613037 batch_id=426:  91%|█████████ | 426/469 [00:14<00:01, 27.83it/s]\u001b[A\n",
            "loss=1.2158108949661255 batch_id=427:  91%|█████████ | 426/469 [00:14<00:01, 27.83it/s]\u001b[A\n",
            "loss=1.0998425483703613 batch_id=428:  91%|█████████ | 426/469 [00:14<00:01, 27.83it/s]\u001b[A\n",
            "loss=1.0998425483703613 batch_id=428:  91%|█████████▏| 429/469 [00:14<00:01, 27.88it/s]\u001b[A\n",
            "loss=1.2247875928878784 batch_id=429:  91%|█████████▏| 429/469 [00:14<00:01, 27.88it/s]\u001b[A\n",
            "loss=1.3606090545654297 batch_id=430:  91%|█████████▏| 429/469 [00:14<00:01, 27.88it/s]\u001b[A\n",
            "loss=0.9736390113830566 batch_id=431:  91%|█████████▏| 429/469 [00:14<00:01, 27.88it/s]\u001b[A\n",
            "loss=1.1681166887283325 batch_id=432:  91%|█████████▏| 429/469 [00:14<00:01, 27.88it/s]\u001b[A\n",
            "loss=1.1681166887283325 batch_id=432:  92%|█████████▏| 433/469 [00:14<00:01, 29.08it/s]\u001b[A\n",
            "loss=1.0580745935440063 batch_id=433:  92%|█████████▏| 433/469 [00:14<00:01, 29.08it/s]\u001b[A\n",
            "loss=1.168326735496521 batch_id=434:  92%|█████████▏| 433/469 [00:14<00:01, 29.08it/s] \u001b[A\n",
            "loss=1.2555285692214966 batch_id=435:  92%|█████████▏| 433/469 [00:14<00:01, 29.08it/s]\u001b[A\n",
            "loss=1.1904691457748413 batch_id=436:  92%|█████████▏| 433/469 [00:14<00:01, 29.08it/s]\u001b[A\n",
            "loss=1.1904691457748413 batch_id=436:  93%|█████████▎| 437/469 [00:14<00:01, 29.71it/s]\u001b[A\n",
            "loss=1.0151402950286865 batch_id=437:  93%|█████████▎| 437/469 [00:14<00:01, 29.71it/s]\u001b[A\n",
            "loss=1.025712013244629 batch_id=438:  93%|█████████▎| 437/469 [00:14<00:01, 29.71it/s] \u001b[A\n",
            "loss=1.238091230392456 batch_id=439:  93%|█████████▎| 437/469 [00:14<00:01, 29.71it/s]\u001b[A\n",
            "loss=0.944577157497406 batch_id=440:  93%|█████████▎| 437/469 [00:14<00:01, 29.71it/s]\u001b[A\n",
            "loss=0.944577157497406 batch_id=440:  94%|█████████▍| 441/469 [00:14<00:00, 30.39it/s]\u001b[A\n",
            "loss=1.0880224704742432 batch_id=441:  94%|█████████▍| 441/469 [00:14<00:00, 30.39it/s]\u001b[A\n",
            "loss=0.9710699915885925 batch_id=442:  94%|█████████▍| 441/469 [00:14<00:00, 30.39it/s]\u001b[A\n",
            "loss=0.9592208862304688 batch_id=443:  94%|█████████▍| 441/469 [00:15<00:00, 30.39it/s]\u001b[A\n",
            "loss=1.1086962223052979 batch_id=444:  94%|█████████▍| 441/469 [00:15<00:00, 30.39it/s]\u001b[A\n",
            "loss=1.1086962223052979 batch_id=444:  95%|█████████▍| 445/469 [00:15<00:00, 30.52it/s]\u001b[A\n",
            "loss=1.260167121887207 batch_id=445:  95%|█████████▍| 445/469 [00:15<00:00, 30.52it/s] \u001b[A\n",
            "loss=1.0661998987197876 batch_id=446:  95%|█████████▍| 445/469 [00:15<00:00, 30.52it/s]\u001b[A\n",
            "loss=1.2751487493515015 batch_id=447:  95%|█████████▍| 445/469 [00:15<00:00, 30.52it/s]\u001b[A\n",
            "loss=1.1609317064285278 batch_id=448:  95%|█████████▍| 445/469 [00:15<00:00, 30.52it/s]\u001b[A\n",
            "loss=1.1609317064285278 batch_id=448:  96%|█████████▌| 449/469 [00:15<00:00, 30.76it/s]\u001b[A\n",
            "loss=1.2158759832382202 batch_id=449:  96%|█████████▌| 449/469 [00:15<00:00, 30.76it/s]\u001b[A\n",
            "loss=0.9560158252716064 batch_id=450:  96%|█████████▌| 449/469 [00:15<00:00, 30.76it/s]\u001b[A\n",
            "loss=1.012235164642334 batch_id=451:  96%|█████████▌| 449/469 [00:15<00:00, 30.76it/s] \u001b[A\n",
            "loss=0.983424723148346 batch_id=452:  96%|█████████▌| 449/469 [00:15<00:00, 30.76it/s]\u001b[A\n",
            "loss=0.983424723148346 batch_id=452:  97%|█████████▋| 453/469 [00:15<00:00, 29.82it/s]\u001b[A\n",
            "loss=1.026369571685791 batch_id=453:  97%|█████████▋| 453/469 [00:15<00:00, 29.82it/s]\u001b[A\n",
            "loss=1.2033382654190063 batch_id=454:  97%|█████████▋| 453/469 [00:15<00:00, 29.82it/s]\u001b[A\n",
            "loss=0.9676419496536255 batch_id=455:  97%|█████████▋| 453/469 [00:15<00:00, 29.82it/s]\u001b[A\n",
            "loss=0.9676419496536255 batch_id=455:  97%|█████████▋| 456/469 [00:15<00:00, 29.73it/s]\u001b[A\n",
            "loss=0.8990651965141296 batch_id=456:  97%|█████████▋| 456/469 [00:15<00:00, 29.73it/s]\u001b[A\n",
            "loss=1.078936219215393 batch_id=457:  97%|█████████▋| 456/469 [00:15<00:00, 29.73it/s] \u001b[A\n",
            "loss=1.009961485862732 batch_id=458:  97%|█████████▋| 456/469 [00:15<00:00, 29.73it/s]\u001b[A\n",
            "loss=0.9690243005752563 batch_id=459:  97%|█████████▋| 456/469 [00:15<00:00, 29.73it/s]\u001b[A\n",
            "loss=0.9690243005752563 batch_id=459:  98%|█████████▊| 460/469 [00:15<00:00, 29.43it/s]\u001b[A\n",
            "loss=1.0942293405532837 batch_id=460:  98%|█████████▊| 460/469 [00:15<00:00, 29.43it/s]\u001b[A\n",
            "loss=1.2578171491622925 batch_id=461:  98%|█████████▊| 460/469 [00:15<00:00, 29.43it/s]\u001b[A\n",
            "loss=1.0275119543075562 batch_id=462:  98%|█████████▊| 460/469 [00:15<00:00, 29.43it/s]\u001b[A\n",
            "loss=0.8921124935150146 batch_id=463:  98%|█████████▊| 460/469 [00:15<00:00, 29.43it/s]\u001b[A\n",
            "loss=0.8921124935150146 batch_id=463:  99%|█████████▉| 464/469 [00:15<00:00, 30.58it/s]\u001b[A\n",
            "loss=1.0084216594696045 batch_id=464:  99%|█████████▉| 464/469 [00:15<00:00, 30.58it/s]\u001b[A\n",
            "loss=0.9855217933654785 batch_id=465:  99%|█████████▉| 464/469 [00:15<00:00, 30.58it/s]\u001b[A\n",
            "loss=1.086441159248352 batch_id=466:  99%|█████████▉| 464/469 [00:15<00:00, 30.58it/s] \u001b[A\n",
            "loss=1.2277369499206543 batch_id=467:  99%|█████████▉| 464/469 [00:15<00:00, 30.58it/s]\u001b[A\n",
            "loss=1.2277369499206543 batch_id=467: 100%|█████████▉| 468/469 [00:15<00:00, 29.81it/s]\u001b[A\n",
            "loss=0.9942758679389954 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9347, Accuracy: 7160/10000 (72%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}